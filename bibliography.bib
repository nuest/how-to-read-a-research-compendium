
@article{sandve_ten_2013,
	title = {Ten {Simple} {Rules} for {Reproducible} {Computational} {Research}},
	volume = {9},
	url = {http://dx.doi.org/10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	number = {10},
	urldate = {2016-02-15},
	journal = {PLoS Comput Biol},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	month = oct,
	year = {2013},
	pages = {e1003285},
	file = {PLoS Full Text PDF:/home/daniel/Zotero/storage/8MIATH2X/Sandve et al. - 2013 - Ten Simple Rules for Reproducible Computational Re.pdf:application/pdf}
}

@article{gentleman_statistical_2007,
	title = {Statistical {Analyses} and {Reproducible} {Research}},
	volume = {16},
	issn = {1061-8600},
	url = {http://dx.doi.org/10.1198/106186007X178663},
	doi = {10.1198/106186007X178663},
	abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents---including figures, tables, and so on---can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection.The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
	number = {1},
	urldate = {2016-02-15},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Gentleman, Robert and Lang, Duncan Temple},
	month = mar,
	year = {2007},
	pages = {1--23},
	file = {Full Text PDF:/home/daniel/Zotero/storage/2JBHR9M8/Gentleman and Lang - 2007 - Statistical Analyses and Reproducible Research.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/IFV7R69I/106186007X178663.html:text/html}
}

@article{nosek_promoting_2015,
	title = {Promoting an open research culture},
	volume = {348},
	copyright = {Copyright © 2015, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/348/6242/1422},
	doi = {10.1126/science.aab2374},
	abstract = {Author guidelines for journals could help to promote transparency, openness, and reproducibility
Author guidelines for journals could help to promote transparency, openness, and reproducibility},
	language = {en},
	number = {6242},
	urldate = {2016-02-16},
	journal = {Science},
	author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. Levy and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
	month = jun,
	year = {2015},
	pmid = {26113702},
	pages = {1422--1425},
	file = {Snapshot:/home/daniel/Zotero/storage/HRMBB3QS/1422.html:text/html}
}

@article{stodden_researchcompendia.org:_2015,
	title = {{ResearchCompendia}.org: {Cyberinfrastructure} for {Reproducibility} and {Collaboration} in {Computational} {Science}},
	volume = {17},
	issn = {1521-9615},
	shorttitle = {{ResearchCompendia}.org},
	url = {http://scitation.aip.org/content/aip/journal/cise/17/1/10.1109/MCSE.2015.18},
	doi = {10.1109/MCSE.2015.18},
	abstract = {We outline three goals to consider in building cyberinfrastructure to support scientific research and dissemination, and present our demonstration project ResearchCompendia. We posit that cyberinfrastructure should reinforce scientific norms, such as transparency and reproducibility, while embedding and encouraging best practices in scientific research, such as citation. Finally, we believe cyberinfrastucture should consider the entire soup-to-nuts discovery pipeline, even if focusing only on a subset of the workflow. In this article, we develop these ideas in the context of the ResearchCompendia project. ResearchCompendia is designed to facilitate reproducibility in computational science by persistently linking data and code that generated published findings to the article, and executing the code in the cloud to validate or certify those findings. We conclude with a discussion of the future vision of cyberinfrastructure and ResearchCompendia in support of science.},
	number = {1},
	urldate = {2016-06-17},
	journal = {Computing in Science \& Engineering},
	author = {Stodden, Victoria and Miguez, Sheila and Seiler, Jennifer},
	month = jan,
	year = {2015},
	keywords = {Cyberinfrastructure, Pipelines},
	pages = {12--19},
	file = {Full Text PDF:/home/daniel/Zotero/storage/98MH2T38/Stodden et al. - 2015 - ResearchCompendia.org Cyberinfrastructure for Rep.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/8U6HNBKI/MCSE.2015.html:text/html}
}

@article{nust_opening_2017,
	title = {Opening the {Publication} {Process} with {Executable} {Research} {Compendia}},
	volume = {23},
	issn = {1082-9873},
	url = {http://www.dlib.org/dlib/january17/nuest/01nuest.html},
	doi = {10.1045/january2017-nuest},
	language = {en},
	number = {1/2},
	urldate = {2017-01-16},
	journal = {D-Lib Magazine},
	author = {Nüst, Daniel and Konkol, Markus and Pebesma, Edzer and Kray, Christian and Schutzeichel, Marc and Przibytzin, Holger and Lorenz, Jörg},
	month = jan,
	year = {2017},
	file = {Opening the Publication Process with Executable Research Compendia:/home/daniel/Zotero/storage/QRSAPWXU/01nuest.html:text/html}
}

@article{keshav_how_2007,
	title = {How to {Read} a {Paper}},
	volume = {37},
	issn = {0146-4833},
	url = {http://doi.acm.org/10.1145/1273445.1273458},
	doi = {10.1145/1273445.1273458},
	abstract = {Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.},
	number = {3},
	urldate = {2016-09-28},
	journal = {SIGCOMM Comput. Commun. Rev.},
	author = {Keshav, S.},
	month = jul,
	year = {2007},
	keywords = {hints, paper, reading},
	pages = {83--84},
	file = {ACM Full Text PDF:/home/daniel/Zotero/storage/5NV74F24/Keshav - 2007 - How to Read a Paper.pdf:application/pdf}
}

@techreport{keshav_how_2016,
	address = {Waterloo, ON, Canada},
	type = {Manuscript},
	title = {How to {Read} a {Paper}},
	url = {http://blizzard.cs.uwaterloo.ca/keshav/home/Papers/data/07/paper-reading.pdf},
	abstract = {Researchers spend a great deal of time reading research papers.  However, this skill is rarely taught, leading to much wasted effort.  This article outlines a practical and efficient three-pass method for  reading  research  papers. I also describe how to use this method to do a literature survey.},
	urldate = {2017-05-10},
	author = {Keshav, S.},
	month = feb,
	year = {2016},
	file = {paper-reading.pdf:/home/daniel/Zotero/storage/QCU24MNU/paper-reading.pdf:application/pdf}
}

@inproceedings{freire_computational_2012,
	address = {New York, NY, USA},
	series = {{SIGMOD} '12},
	title = {Computational {Reproducibility}: {State}-of-the-art, {Challenges}, and {Database} {Research} {Opportunities}},
	isbn = {978-1-4503-1247-9},
	shorttitle = {Computational {Reproducibility}},
	url = {http://doi.acm.org/10.1145/2213836.2213908},
	doi = {10.1145/2213836.2213908},
	abstract = {Computational experiments have become an integral part of the scientific method, but reproducing, archiving, and querying them is still a challenge. The first barrier to a wider adoption is the fact that it is hard both for authors to derive a compendium that encapsulates all the components needed to reproduce a result and for reviewers to verify the results. In this tutorial, we will present a series of guidelines and, through hands-on examples, review existing tools to help authors create of reproducible results. We will also outline open problems and new directions for database-related research having to do with querying computational experiments.},
	urldate = {2017-03-14},
	booktitle = {Proceedings of the 2012 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Freire, Juliana and Bonnet, Philippe and Shasha, Dennis},
	year = {2012},
	keywords = {computational reproducibility, reproducible publications},
	pages = {593--596},
	file = {ACM Full Text PDF:/home/daniel/Zotero/storage/B976MV62/Freire et al. - 2012 - Computational Reproducibility State-of-the-art, C.pdf:application/pdf}
}

@article{peng_reproducible_2006,
	title = {Reproducible {Epidemiologic} {Research}},
	volume = {163},
	issn = {0002-9262, 1476-6256},
	url = {http://aje.oxfordjournals.org/content/163/9/783},
	doi = {10.1093/aje/kwj093},
	abstract = {The replication of important findings by multiple independent investigators is fundamental to the accumulation of scientific evidence. Researchers in the biologic and physical sciences expect results to be replicated by independent data, analytical methods, laboratories, and instruments. Epidemiologic studies are commonly used to quantify small health effects of important, but subtle, risk factors, and replication is of critical importance where results can inform substantial policy decisions. However, because of the time, expense, and opportunism of many current epidemiologic studies, it is often impossible to fully replicate their findings. An attainable minimum standard is “reproducibility,” which calls for data sets and software to be made available for verifying published findings and conducting alternative analyses. The authors outline a standard for reproducibility and evaluate the reproducibility of current epidemiologic research. They also propose methods for reproducible research and implement them by use of a case study in air pollution and health.},
	language = {en},
	number = {9},
	urldate = {2016-05-25},
	journal = {American Journal of Epidemiology},
	author = {Peng, Roger D. and Dominici, Francesca and Zeger, Scott L.},
	month = may,
	year = {2006},
	pmid = {16510544},
	keywords = {NMMAPS, National Morbidity, Mortality, and Air Pollution Study, air pollution, information dissemination, models, statistical},
	pages = {783--789},
	file = {Full Text PDF:/home/daniel/Zotero/storage/NEKBTNXT/Peng et al. - 2006 - Reproducible Epidemiologic Research.pdf:application/pdf;Reproducible Epidemiologic Research.pdf:/home/daniel/Zotero/storage/NYLLHUTJ/Reproducible Epidemiologic Research.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/QWH5JATA/783.html:text/html}
}

@article{vandevalle_code_2012,
	title = {Code sharing is associated with research impact in image processing},
	volume = {Reproducible Research for Scientific Computing},
	abstract = {In computational sciences such as image processing, publishing usually isn’t enough to
allow other researchers to verify results. Often, supplementary materials such as source
code and measurement data are required. Yet most researchers choose not to make their
code available because of the extra time required to prepare it. Are such efforts actually
worthwhile, though?},
	journal = {Computing in Science \& Engineering},
	author = {Vandevalle, Patrick},
	month = jul,
	year = {2012},
	pages = {42--47},
	file = {Code sharing is associated with research impact.pdf:/home/daniel/Zotero/storage/QXYS93Y2/Code sharing is associated with research impact.pdf:application/pdf}
}

@misc{marwick_benmarwick/researchcompendium:_2018,
	title = {benmarwick/researchcompendium: {This} is an empty repo created as an aide-mémoire for when {I} start a new project},
	url = {https://github.com/benmarwick/researchcompendium},
	urldate = {2016-12-07},
	author = {Marwick, Ben},
	year = {2018},
	file = {benmarwick/researchcompendium\: This is an empty repo created as an aide-mémoire for when I start a new project:/home/daniel/Zotero/storage/S98UDR7P/researchcompendium.html:text/html}
}

@misc{whitaker_publishing_2017,
	title = {Publishing a reproducible paper},
	url = {https://figshare.com/articles/Publishing_a_reproducible_paper/5440621},
	abstract = {Presented at the Open Science in Practice Summer School (https://osip2017.epfl.ch/page-145979.html) September 2017Abstract: This talk will discuss the perceived and 
actual barriers experienced by researchers attempting to do reproducible
research, and give practical guidance on how they can be overcome. It
will include suggestions on how to make your code and data available and
usable for others (including a strong suggestion to document it clearly
so you don't have to reply to lots of email questions from future
users). Dr Kirstie Whitaker will present example publications from the Neuroscience in Psychiatry Network
and discuss how the consortium has overcome challenges related to
maintaining the privacy of our participants, complying with
institutional ethical review boards, and building skills for individual
researchers. She will encourage summer school participants to take steps
towards ensuring that their publications are as open and reproducible
as possible. The take home message will be: every little counts, and
every journey starts with a single step.},
	urldate = {2017-10-11},
	author = {Whitaker, Kirstie},
	month = sep,
	year = {2017},
	doi = {10.6084/m9.figshare.5440621.v2},
	keywords = {reproducible research, open science},
	file = {Figshare Snapshot:/home/daniel/Zotero/storage/CD3IJ68B/5440621.pdf:application/pdf}
}

@article{barnes_publish_2010,
	title = {Publish your computer code: it is good enough},
	volume = {467},
	copyright = {© 2010 Nature Publishing Group},
	issn = {0028-0836},
	shorttitle = {Publish your computer code},
	url = {http://www.nature.com/news/2010/101013/full/467753a.html},
	doi = {10.1038/467753a},
	abstract = {Nature - the world's best science and medicine on your desktop},
	language = {en},
	number = {7317},
	urldate = {2016-06-28},
	journal = {Nature News},
	author = {Barnes, Nick},
	month = oct,
	year = {2010},
	pages = {753--753},
	file = {Full Text PDF:/home/daniel/Zotero/storage/3MTQ3NZK/Barnes - 2010 - Publish your computer code it is good enough.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/FZ2VFHDJ/467753a.html:text/html}
}

@article{prlic_ten_2012,
	title = {Ten {Simple} {Rules} for the {Open} {Development} of {Scientific} {Software}},
	volume = {8},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002802},
	doi = {10.1371/journal.pcbi.1002802},
	number = {12},
	urldate = {2016-03-14},
	journal = {PLOS Comput Biol},
	author = {Prlić, Andreas and Procter, James B.},
	month = dec,
	year = {2012},
	keywords = {Computer software, bioinformatics, software development, Eyes, Research grants, Open source software, Source code, Scientists},
	pages = {e1002802},
	file = {Ben Morris' notebook\: What incentives are there to maintain software in academia?:/home/daniel/Zotero/storage/6MWN83XL/what-incentives-are-there-to-maintain.html:text/html;Full Text PDF:/home/daniel/Zotero/storage/F2Q7J33W/Prlić and Procter - 2012 - Ten Simple Rules for the Open Development of Scien.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/S67TD657/article.html:text/html}
}

@article{taschuk_ten_2017,
	title = {Ten simple rules for making research software more robust},
	volume = {13},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005412},
	doi = {10.1371/journal.pcbi.1005412},
	abstract = {Author summary Many researchers have found out the hard way that there’s a world of difference between “works for me on my machine” and “works for other people on theirs.” Many common challenges can be avoided by following a few simple rules; doing so not only improves reproducibility but can accelerate research.},
	number = {4},
	urldate = {2017-04-18},
	journal = {PLOS Computational Biology},
	author = {Taschuk, Morgan and Wilson, Greg},
	month = apr,
	year = {2017},
	keywords = {Computer software, bioinformatics, Operating Systems, Reproducibility, software development, Software tools, Software Engineering, Sequence alignment},
	pages = {e1005412},
	file = {Full Text PDF:/home/daniel/Zotero/storage/TZZABIZB/Taschuk and Wilson - 2017 - Ten simple rules for making research software more.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/NBNZT2Z3/article.pdf:application/pdf}
}

@inproceedings{jimenez_popper_2017,
	title = {The {Popper} {Convention}: {Making} {Reproducible} {Systems} {Evaluation} {Practical}},
	shorttitle = {The {Popper} {Convention}},
	doi = {10.1109/IPDPSW.2017.157},
	abstract = {Independent validation of experimental results in the field of systems research is a challenging task, mainly due to differences in software and hardware in computational environments. Recreating an environment that resembles the original is difficult and time-consuming. In this paper we introduce \_Popper\_, a convention based on a set of modern open source software (OSS) development principles for generating reproducible scientific publications. Concretely, we make the case for treating an article as an OSS project following a DevOps approach and applying software engineering best-practices to manage its associated artifacts and maintain the reproducibility of its findings. Popper leverages existing cloud-computing infrastructure and DevOps tools to produce academic articles that are easy to validate and extend. We present a use case that illustrates the usefulness of this approach. We show how, by following the \_Popper\_ convention, reviewers and researchers can quickly get to the point of getting results without relying on the original author's intervention.},
	booktitle = {2017 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} {Workshops} ({IPDPSW})},
	author = {Jimenez, I. and Sevilla, M. and Watkins, N. and Maltzahn, C. and Lofstead, J. and Mohror, K. and Arpaci-Dusseau, A. and Arpaci-Dusseau, R.},
	month = may,
	year = {2017},
	keywords = {Software, natural sciences computing, Virtual machining, reproducibility, repeatability, Tools, software engineering, public domain software, replicability, Automation, cloud computing, cloud-computing infrastructure, computational environments, DevOps approach, DevOps tools, Guidelines, open source software development principles, OSS project, Packaging, Popper convention, reproducible scientific publications, reproducible systems evaluation, state of the practice, systems research, Virtualization},
	pages = {1561--1570},
	file = {IEEE Xplore Abstract Record:/home/daniel/Zotero/storage/E4WWH5FN/7965226.html:text/html;Introduction to Popper Pipelines — Sphinx with Markdown 0.1.0 documentation:/home/daniel/Zotero/storage/3EMEHDEK/intro_to_popper.html:text/html;Jimenez et al. - 2017 - The Popper Convention Making Reproducible Systems.pdf:/home/daniel/Zotero/storage/TFVGZIKB/Jimenez et al. - 2017 - The Popper Convention Making Reproducible Systems.pdf:application/pdf}
}

@article{stodden_legal_2009,
	title = {The {Legal} {Framework} for {Reproducible} {Scientific} {Research}: {Licensing} and {Copyright}},
	volume = {11},
	issn = {1521-9615},
	shorttitle = {The {Legal} {Framework} for {Reproducible} {Scientific} {Research}},
	url = {https://aip.scitation.org/doi/abs/10.1109/MCSE.2009.19},
	doi = {10.1109/MCSE.2009.19},
	number = {1},
	urldate = {2018-05-14},
	journal = {Computing in Science \& Engineering},
	author = {Stodden, Victoria},
	month = jan,
	year = {2009},
	pages = {35--40},
	file = {Full Text PDF:/home/daniel/Zotero/storage/VKLQGSF9/Stodden - 2009 - The Legal Framework for Reproducible Scientific Re.pdf:application/pdf}
}

@techreport{marwick_packaging_2017,
	title = {Packaging data analytical work reproducibly using {R} (and friends)},
	url = {https://peerj.com/preprints/3192},
	abstract = {Computers are a central tool in the research process, enabling complex and large scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognisable way for organising the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
	language = {en},
	number = {e3192v1},
	urldate = {2018-05-14},
	institution = {PeerJ Inc.},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	month = aug,
	year = {2017},
	doi = {10.7287/peerj.preprints.3192v1},
	file = {Full Text PDF:/home/daniel/Zotero/storage/XZDXW465/Marwick et al. - 2017 - Packaging data analytical work reproducibly using .pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/YVY2GWVW/3192v1.html:text/html}
}

@article{konkol_-depth_2018,
	title = {In-depth examination of spatio-temporal figures in open reproducible research},
	url = {https://eartharxiv.org/q53m8/},
	doi = {10.17605/OSF.IO/Q53M8},
	abstract = {Figures such as maps and time series are essential means to visualize spatio-temporal
results in scientific papers. Being able to recompute them using the underlying source
code and data is thus a core aspect in reproducible research. However, many scientists
see the preparation of code and data for publication as an additional burden
without immediate benefits. In this work, we investigate advantages and new capabilities
of reproducible research papers. Our key contributions are (i) the extension
of a geoscientist’s workflow while examining papers including reproducible figures
such as maps and (ii) the prototypical implementation of the workflow as a web
application. The workflow is based on current practices of geoscientists and encapsulates
benefits of reproducible figures. It is informed by ideas and needs identified
by geoscientists in a survey, interviews, and a focus group. Based on their statements,
we first extend the traditional workflow steps Discovery and Inspection by
additional capabilities and propose two new steps: Manipulation of the content of
a spatio-temporal figure and Substitution of the underlying code and data. The extended
workflow and its implementation might facilitate in-depth examination and
reusability of geoscientific results.},
	urldate = {2018-05-14},
	journal = {EarthArXiv},
	author = {Konkol, Markus and Kray, Christian},
	month = apr,
	year = {2018},
	file = {Full Text PDF:/home/daniel/Zotero/storage/LTQJAYLQ/Konkol and Kray - 2018 - In-depth examination of spatio-temporal figures in.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/HV6GHDXX/q53m8.html:text/html}
}

@article{roscoe_writing_2007,
	title = {Writing reviews for systems conferences},
	url = {https://people.inf.ethz.ch/troscoe/pubs/review-writing.pdf},
	language = {en},
	author = {Roscoe, Timothy},
	month = mar,
	year = {2007},
	pages = {6},
	file = {Roscoe - Writing reviews for systems conferences.pdf:/home/daniel/Zotero/storage/3Q67NDRM/Roscoe - Writing reviews for systems conferences.pdf:application/pdf}
}

@book{mclean_literature_2012,
	title = {Literature {Review} {Matrix}},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {http://archive.org/details/LiteratureReviewMatrix},
	abstract = {A simple matrix to make compiling literature for review a lot easier. Simply follow the guide and fill in the blanks. The text boxes are small on purpose - you have to be succinct! If you understand the paper you'll be able to paraphrase it to fit in the space provided, which means hopefully you're read, assimilated and fully understood the data.},
	urldate = {2018-05-25},
	author = {McLean, Iain H.},
	month = oct,
	year = {2012},
	keywords = {psychology, academic paper, literature review}
}

@misc{peyton_jones_simon_nodate,
	title = {Simon {Peyton} {Jones} at {Microsoft} {Research}},
	url = {https://www.microsoft.com/en-us/research/people/simonpj/},
	abstract = {I’m a researcher at Microsoft Research in Cambridge, England. I started here in Sept 1998. I’m also an Honorary Professor of the Computing Science Department at Glasgow University, where I was a professor during 1990-1998.

I am married to Dorothy, a priest in the Church of England. We have six children.

I’m interested in the design, implementation, and application of lazy functional languages. In practical terms, that means I spend a most of my time on the design and implementation of the language Haskell. In particular, much of my work is focused around the Glasgow Haskell Compiler, and its ramifications.

I am chair of Computing at School, the group at the epicentre of the reform of the national curriculum for Computing in England.   Computer science is now a foundational subject, alongside maths and natural science, that every child learns from primary school onwards (background here).},
	language = {en-US},
	urldate = {2018-05-25},
	journal = {Simon Peyton Jones at Microsoft Research},
	author = {Peyton Jones, Simon},
	file = {Snapshot:/home/daniel/Zotero/storage/VBNNM98D/simonpj.html:text/html}
}

@misc{schulzrinne_writing_nodate,
	title = {Writing {Systems} and {Networking} {Articles}},
	url = {https://www.cs.columbia.edu/~hgs/etc/writing-style.html},
	urldate = {2018-05-25},
	author = {Schulzrinne, Henning},
	file = {Writing Systems and Networking Articles:/home/daniel/Zotero/storage/G2IMXL4T/writing-style.html:text/html}
}

@article{whitesides_whitesides_2004,
	title = {Whitesides' {Group}: {Writing} a {Paper}},
	volume = {16},
	copyright = {Copyright © 2004 WILEY‐VCH Verlag GmbH \& Co. KGaA, Weinheim},
	issn = {1521-4095},
	shorttitle = {Whitesides' {Group}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adma.200400767},
	doi = {10.1002/adma.200400767},
	abstract = {Insights into conducting research and the writing of scientific papers are given by Prof. Whitesides in this short essay. The manuscript and its guidelines has been circulated within the Whitesides' research group since 1989.},
	number = {15},
	urldate = {2018-05-25},
	journal = {Advanced Materials},
	author = {Whitesides, G. M.},
	month = aug,
	year = {2004},
	pages = {1375--1377},
	file = {Full Text PDF:/home/daniel/Zotero/storage/KKE5VYXP/Whitesides - Whitesides' Group Writing a Paper.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/4KCAR7KH/adma.html:text/html}
}

@unpublished{pebesma_earth_2013,
	title = {Earth and {Planetary} {Innovation} {Challenge} ({EPIC}) submission "{One}-{Click}-{Reproduce}"},
	url = {http://pebesma.staff.ifgi.de/epic.pdf},
	abstract = {esearchers face an increasing need to share the input data, data created, and  analysis  steps  along  with  published  papers,  in  order  to  allow  readers  to reproduce  their  analysis.   This 
submission  explains  how  Elsevier  journals  can
enable this, with focus on the R environment (http://www.r-project.org/).},
	language = {en},
	author = {Pebesma, Edzer},
	month = oct,
	year = {2013},
	file = {Pebesma - httpwww.elsevier-epic.com -.pdf:/home/daniel/Zotero/storage/L7JDAK7L/Pebesma - httpwww.elsevier-epic.com -.pdf:application/pdf}
}

@article{barba_terminologies_2018,
	title = {Terminologies for {Reproducible} {Research}},
	url = {http://arxiv.org/abs/1802.03311},
	abstract = {Reproducible research---by its many names---has come to be regarded as a key concern across disciplines and stakeholder groups. Funding agencies and journals, professional societies and even mass media are paying attention, often focusing on the so-called "crisis" of reproducibility. One big problem keeps coming up among those seeking to tackle the issue: different groups are using terminologies in utter contradiction with each other. Looking at a broad sample of publications in different fields, we can classify their terminology via decision tree: they either, A---make no distinction between the words reproduce and replicate, or B---use them distinctly. If B, then they are commonly divided in two camps. In a spectrum of concerns that starts at a minimum standard of "same data+same methods=same results," to "new data and/or new methods in an independent study=same findings," group 1 calls the minimum standard reproduce, while group 2 calls it replicate. This direct swap of the two terms aggravates an already weighty issue. By attempting to inventory the terminologies across disciplines, I hope that some patterns will emerge to help us resolve the contradictions.},
	urldate = {2018-02-26},
	journal = {arXiv:1802.03311 [cs]},
	author = {Barba, Lorena A.},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.03311},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv\:1802.03311 PDF:/home/daniel/Zotero/storage/9D65Y4CZ/Barba - 2018 - Terminologies for Reproducible Research.pdf:application/pdf;arXiv.org Snapshot:/home/daniel/Zotero/storage/ZYXPRXGW/1802.html:text/html}
}

@misc{claerbout_seventeen_1994,
	title = {Seventeen years of super computing},
	url = {http://sepwww.stanford.edu/sep/jon/nrc.html},
	urldate = {2018-05-25},
	author = {Claerbout, Jon},
	month = oct,
	year = {1994},
	file = {Seventeen years of super computing:/home/daniel/Zotero/storage/TBI3NZF5/nrc.html:text/html}
}

@article{stodden_best_2014,
	title = {Best {Practices} for {Computational} {Science}: {Software} {Infrastructure} and {Environments} for {Reproducible} and {Extensible} {Research}},
	volume = {2},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2049-9647},
	shorttitle = {Best {Practices} for {Computational} {Science}},
	url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.ay/},
	doi = {10.5334/jors.ay},
	abstract = {The goal of this article is to coalesce a discussion around best practices for scholarly research that utilizes computational methods, by providing a formalized set of best practice recommendations to guide computational scientists and other stakeholders wishing to disseminate reproducible research, facilitate innovation by enabling data and code re-use, and enable broader communication of the output of computational scientific research. Scholarly dissemination and communication standards are changing to reflect the increasingly computational nature of scholarly research, primarily to include the sharing of the data and code associated with published results. We also present these Best Practices as a living, evolving, and changing document at http://wiki.stodden.net/Best\_Practices.},
	language = {en},
	number = {1},
	urldate = {2018-05-25},
	journal = {Journal of Open Research Software},
	author = {Stodden, Victoria and Miguez, Sheila},
	month = jul,
	year = {2014},
	keywords = {reproducible research, best practices, archiving, data sharing, code sharing, wiki, computational science, scientific method, open science},
	file = {Full Text PDF:/home/daniel/Zotero/storage/9F4FSZDK/Stodden and Miguez - 2014 - Best Practices for Computational Science Software.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/YA484MMP/jors.html:text/html}
}

@article{wilson_good_2017,
	title = {Good enough practices in scientific computing},
	volume = {13},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
	doi = {10.1371/journal.pcbi.1005510},
	abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
	number = {6},
	urldate = {2017-07-20},
	journal = {PLOS Computational Biology},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = jun,
	year = {2017},
	keywords = {Computer software, Reproducibility, Source code, Software tools, data management, Data processing, Control systems, Programming languages},
	pages = {e1005510},
	file = {Full Text PDF:/home/daniel/Zotero/storage/9RQBDFVM/Wilson et al. - 2017 - Good enough practices in scientific computing.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/XTX9RGLV/article.html:text/html}
}

@article{marwick_packaging_2018,
	title = {Packaging {Data} {Analytical} {Work} {Reproducibly} {Using} {R} (and {Friends})},
	volume = {72},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2017.1375986},
	doi = {10.1080/00031305.2017.1375986},
	abstract = {Computers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognizable way for organizing the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
	number = {1},
	urldate = {2018-05-25},
	journal = {The American Statistician},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	month = jan,
	year = {2018},
	keywords = {Open source software, Computational science, Data science, Reproducible research},
	pages = {80--88},
	file = {Snapshot:/home/daniel/Zotero/storage/BZ7KT8CB/00031305.2017.html:text/html}
}

@techreport{marwick_packaging_2018-1,
	title = {Packaging data analytical work reproducibly using {R} (and friends)},
	url = {https://peerj.com/preprints/3192},
	abstract = {Computers are a central tool in the research process, enabling complex and large scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognisable way for organising the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
	language = {en},
	number = {e3192v2},
	urldate = {2018-05-25},
	institution = {PeerJ Inc.},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	month = mar,
	year = {2018},
	doi = {10.7287/peerj.preprints.3192v2},
	file = {Full Text PDF:/home/daniel/Zotero/storage/9S8IS8EQ/Marwick et al. - 2018 - Packaging data analytical work reproducibly using .pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/X89N6894/3192.html:text/html}
}

@article{knuth_literate_1984,
	title = {Literate {Programming}},
	volume = {27},
	issn = {0010-4620},
	url = {http://dx.doi.org/10.1093/comjnl/27.2.97},
	doi = {10.1093/comjnl/27.2.97},
	number = {2},
	urldate = {2016-03-04},
	journal = {Comput. J.},
	author = {Knuth, Donald E.},
	month = may,
	year = {1984},
	pages = {97--111}
}

@article{baker_muddled_2016,
	title = {Muddled meanings hamper efforts to fix reproducibility crisis},
	issn = {1476-4687},
	url = {http://www.nature.com/doifinder/10.1038/nature.2016.20076},
	doi = {10.1038/nature.2016.20076},
	urldate = {2016-06-28},
	journal = {Nature},
	author = {Baker, Monya},
	month = jun,
	year = {2016}
}

@article{brinckman_computing_2018,
	title = {Computing environments for reproducibility: {Capturing} the “{Whole} {Tale}”},
	issn = {0167-739X},
	shorttitle = {Computing environments for reproducibility},
	url = {http://www.sciencedirect.com/science/article/pii/S0167739X17310695},
	doi = {10.1016/j.future.2017.12.029},
	abstract = {The act of sharing scientific knowledge is rapidly evolving away from traditional articles and presentations to the delivery of executable objects that integrate the data and computational details (e.g., scripts and workflows) upon which the findings rely. This envisioned coupling of data and process is essential to advancing science but faces technical and institutional barriers. The Whole Tale project aims to address these barriers by connecting computational, data-intensive research efforts with the larger research process—transforming the knowledge discovery and dissemination process into one where data products are united with research articles to create “living publications” or tales. The Whole Tale focuses on the full spectrum of science, empowering users in the long tail of science, and power users with demands for access to big data and compute resources. We report here on the design, architecture, and implementation of the Whole Tale environment.},
	urldate = {2018-04-17},
	journal = {Future Generation Computer Systems},
	author = {Brinckman, Adam and Chard, Kyle and Gaffney, Niall and Hategan, Mihael and Jones, Matthew B. and Kowalik, Kacper and Kulasekaran, Sivakumar and Ludäscher, Bertram and Mecum, Bryce D. and Nabrzyski, Jarek and Stodden, Victoria and Taylor, Ian J. and Turk, Matthew J. and Turner, Kandace},
	month = feb,
	year = {2018},
	keywords = {Reproducibility, Data sharing, Code sharing, Living publications, Provenance},
	file = {ScienceDirect Full Text PDF:/home/daniel/Zotero/storage/RP5UKQYS/Brinckman et al. - 2018 - Computing environments for reproducibility Captur.pdf:application/pdf;ScienceDirect Snapshot:/home/daniel/Zotero/storage/7WLIMQK4/S0167739X17310695.html:text/html}
}

@article{forde_post-training_nodate,
	title = {Post-{Training} {Evaluation} with {Binder}},
	abstract = {Black box’ models are increasingly prevalent in our world and have important societal impacts, but are often difficult to scrutinize or evaluate for bias. Binder provides anyone in the community the opportunity to examine a machine learning pipeline, promoting fairness, accountability, and transparency. Binder is used to create custom computing environments that can be shared and used by many remote users, enabling the user to build and register a Docker image from a repository and connect with JupyterHub. Users can select a specific branch name, commit, or tag to serve. Binder combines two projects: JupyterHub, which provides a scalable system for authenticating users and launching Jupyter Notebook servers, and repo2docker, which generates a Docker image from a Git repository. When connected with JupyterLab, users can navigate a repository on Binder with an IDE as if they were developing the project locally and can explore all underlying data (CSV, JSON, image, etc.). JupyterHub, repo2docker, and JupyterLab work together on Binder to allow a user to evaluate a machine learning pipeline with much greater transparency than a typical publication or GitHub page. Together, these three projects promote fairness, accountability, and transparency in machine learning.},
	language = {en},
	author = {Forde, Jessica and Holdgraf, Chris and Panda, Yuvi and Culich, Aaron and Bussonnier, Matthias},
	pages = {4},
	file = {Forde et al. - Post-Training Evaluation with Binder.pdf:/home/daniel/Zotero/storage/KQXCDRVT/Forde et al. - Post-Training Evaluation with Binder.pdf:application/pdf}
}

@article{thomas_jupyter_2016,
	title = {Jupyter {Notebooks} - a publishing format for reproducible computational workflows},
	copyright = {©2016 \&copy; The authors and IOS Press.},
	issn = {0000-0000},
	url = {http://ebooks.iospress.nl/publication/42900},
	doi = {10.3233/978-1-61499-649-1-87},
	abstract = {It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.},
	urldate = {2018-05-25},
	journal = {Stand Alone},
	author = {Thomas, Kluyver and Benjamin, Ragan-Kelley and Fernando, P\&eacute;rez and Brian, Granger and Matthias, Bussonnier and Jonathan, Frederic and Kyle, Kelley and Jessica, Hamrick and Jason, Grout and Sylvain, Corlay and Paul, Ivanov and Dami\&aacute;n, Avila and Safia, Abdalla and Carol, Willing and Team, Jupyter Development},
	year = {2016},
	pages = {87--90},
	file = {Thomas et al. - 2016 - Jupyter Notebooks &ndash\; a publishing format for .pdf:/home/daniel/Zotero/storage/JLB2N8N3/Thomas et al. - 2016 - Jupyter Notebooks &ndash\; a publishing format for .pdf:application/pdf}
}

@article{kluyver_jupyter_2016,
	title = {Jupyter {Notebooks} - a publishing format for reproducible computational workflows},
	url = {http://ebooks.iospress.nl/publication/42900},
	doi = {10.3233/978-1-61499-649-1-87},
	abstract = {It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.},
	journal = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
	author = {Kluyver, Thomas and Ragan-Kelley, Benjamin and Pérez, Fernando and Granger, Brian and Bussonier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica and Grout, Jason and Corlay, Sylvan and Ivanov, Paul and Avila, Damián and Abdallan, Safia and Willing, Carol and Jupyter Development Team},
	year = {2016},
	pages = {87--90},
	file = {Loizides_Schmidt.pdf:/home/daniel/Zotero/storage/CLSAM83V/Loizides_Schmidt.pdf:application/pdf;Thomas et al. - 2016 - Jupyter Notebooks &ndash\; a publishing format for .pdf:/home/daniel/Zotero/storage/M9D9S9L7/Thomas et al. - 2016 - Jupyter Notebooks &ndash\; a publishing format for .pdf:application/pdf}
}

@misc{ropensci_ropensci_2017,
	title = {{rOpenSci} {Analysis} {Guide} (unconf 2017)},
	url = {https://docs.google.com/document/d/1OYcWJUk-MiM2C1TIHB1Rn6rXoF5fHwRX-7_C12Blx8g/edit?usp=embed_facebook},
	abstract = {rOpenSci(?) Analysis Best Practice Guidelines Developed at rOpenSci unconf 2017 Review guide for analysis best practiceRelated: checkers - a package to assess analysis Reference/template: rOpenSci packaging guide  Analysis workflow and best practices are organized by priority and subdivided into...},
	language = {en-GB},
	urldate = {2018-05-25},
	journal = {Google Docs},
	author = {{rOpenSci}},
	year = {2017},
	file = {Snapshot:/home/daniel/Zotero/storage/5HR9XYR3/edit.html:text/html}
}

@misc{decicco_checkers:_2018,
	title = {checkers: {Automated} checking of best practices for research compendia},
	shorttitle = {checkers},
	url = {https://github.com/ropenscilabs/checkers},
	abstract = {Automated checking of best practices for research compendia},
	urldate = {2018-05-25},
	publisher = {rOpenSci Labs},
	author = {DeCicco, Laura and Ross, Noam and Daish, Alice and Lewis, Molly and Randhawa, Nistara and Boettiger, Carl and Gehlenborg, Nils and Thompson, Jennifer and Tierney, Nicholas},
	month = may,
	year = {2018},
	note = {original-date: 2017-05-25T18:36:09Z},
	keywords = {unconf17}
}

@article{kahneman_new_2014,
	title = {A new etiquette for replication},
	volume = {45},
	issn = {0147-829X},
	abstract = {The author shares the common position that replications play an important role in our science—to some extent by cleaning up the scientific record, mostly by deterring sloppy research. However, the author believes that current norms allow replicators too much freedom to define their study as a direct replication of previous research. Authors, whose work and reputation are at stake, should have the right to participate as advisors in the replication of their research. The obligation to consult a possibly reluctant author undoubtedly complicates life for replicators, but the burden is not crippling. Firm standards that support the active involvement of authors will contribute both to the fairness of the process and to the scientific quality of replication research. (PsycINFO Database Record (c) 2014 APA, all rights reserved)},
	number = {4},
	journal = {Soc. Psychol.},
	author = {Kahneman, Daniel},
	year = {2014},
	keywords = {author involvement, replication research, scientific quality},
	pages = {310},
	file = {Kahneman - 2014 - A new etiquette for replication.pdf:/home/daniel/Zotero/storage/IK7966QF/Kahneman - 2014 - A new etiquette for replication.pdf:application/pdf}
}

@article{ioannidis_how_2014,
	title = {How to {Make} {More} {Published} {Research} {True}},
	volume = {11},
	issn = {1549-1676},
	url = {http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001747},
	doi = {10.1371/journal.pmed.1001747},
	abstract = {In a 2005 paper that has been accessed more than a million times, John Ioannidis explained why most published research findings were false. Here he revisits the topic, this time to address how to improve matters. Please see later in the article for the Editors' Summary},
	number = {10},
	urldate = {2017-01-04},
	journal = {PLOS Medicine},
	author = {Ioannidis, John P. A.},
	month = oct,
	year = {2014},
	keywords = {Clinical trials, Drug research and development, Peer review, Reproducibility, Research design, Research validity, Scientists, Statistical methods},
	pages = {e1001747},
	file = {Full Text PDF:/home/daniel/Zotero/storage/UN9ETYDR/Ioannidis - 2014 - How to Make More Published Research True.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/GVFMJVH6/article.html:text/html}
}

@article{konkol_state_2018,
	title = {The state of reproducibility in the computational geosciences},
	url = {https://eartharxiv.org/kzu8e/},
	doi = {10.17605/osf.io/kzu8e},
	abstract = {Figures are essential outputs of computational geoscientific research, e.g. maps and time series showing the results of spatiotemporal analyses. They also play a key role in open reproducible research, where public access is provided to paper, data, and source code to enable reproduction of the reported results. This scientific ideal is rarely practiced as studies, e.g. in biology have shown. In this article, we report on a series of studies to evaluate open reproducible research in the geosciences from the perspectives of authors and readers. First, we asked geoscientists what they understand by open reproducible research and what hinders its realisation. We found there is disagreement amongst authors, and a lack of openness impedes the adoption by authors and readers alike. However, reproducible research also includes the ability to achieve the same results requiring not only accessible but executable source code. Hence, to further examine the reader’s perspective, we searched for open access papers from the geosciences that have code/data attached (in R) and executed the analysis. We encountered several technical issues while executing the code and found differences between the original and reproduced figures. Based on these findings, we propose guidelines for authors to address these.},
	urldate = {2018-06-01},
	author = {Konkol, Markus and Kray, Christian and Pfeiffer, Max},
	year = {2018},
	file = {Konkol et al. - 2018 - The state of reproducibility in the computational .pdf:/home/daniel/Zotero/storage/SGHXH76H/Konkol et al. - 2018 - The state of reproducibility in the computational .pdf:application/pdf}
}

@article{green_computational_2018,
	title = {Computational {Reproducibility} via {Containers} in {Social} {Psychology}},
	url = {https://psyarxiv.com/mf82t/},
	doi = {10.17605/OSF.IO/MF82T},
	abstract = {Scientific progress relies on the replication and reuse of research. However, despite an emerging culture of sharing code and data in psychology, the research practices needed to achieve computational reproducibility -- the quality of a research project entailing the provision of sufficient code, data and documentation to allow an independent researcher to re-obtain the project's results -- are not widely adopted. Historically, the ability to share and reuse computationally reproducible research was technically challenging and time-consuming. One welcome development on this front is the advent of containers, a technology intended to facilitate code sharing for software development. Containers, however, remain technically demanding and imperfectly suited for research applications. This editorial argues that the use of containers adapted for research can help foster a culture of reproducibiliy in psychology research. We will illustrate this by introducing Code Ocean, an online computational reproducibility platform. (Disclaimer: both authors work for Code Ocean.)},
	urldate = {2018-04-17},
	journal = {PsyArXiv},
	author = {Green, Seth Ariel and Clyburne-Sherin, April},
	month = feb,
	year = {2018},
	file = {Full Text PDF:/home/daniel/Zotero/storage/NDCXU2RD/Green and Clyburne-Sherin - 2018 - Computational Reproducibility via Containers in So.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/3FEB9BM3/mf82t.html:text/html}
}